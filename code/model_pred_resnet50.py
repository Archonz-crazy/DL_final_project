# -*- coding: utf-8 -*-
"""DL_final_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CfvcDk6iFCHpRkHJHdYa4il7mSr9OCVQ
"""

from google.colab import files
files.upload()  # Use this to upload kaggle.json

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download -d elmadafri/the-wildfire-dataset

! kaggle datasets download -d anamibnjafar0/flamevision

! unzip the-wildfire-dataset.zip

! mv /content/Classification1/the_wildfire_dataset/test/fire/Both_smoke_and_fire/* /content/Classification1/the_wildfire_dataset/test/fire
! mv /content/Classification1/the_wildfire_dataset/test/fire/Smoke_from_fires/* /content/Classification1/the_wildfire_dataset/test/fire
! mv /content/Classification1/the_wildfire_dataset/test/nofire/Fire_confounding_elements/* /content/Classification1/the_wildfire_dataset/test/nofire
! mv /content/Classification1/the_wildfire_dataset/test/nofire/Forested_areas_without_confounding_elements/* /content/Classification1/the_wildfire_dataset/test/nofire
! mv /content/Classification1/the_wildfire_dataset/test/nofire/Smoke_confounding_elements/* /content/Classification1/the_wildfire_dataset/test/nofire

! mv /content/Classification1/the_wildfire_dataset/train/fire/Both_smoke_and_fire/* /content/Classification1/the_wildfire_dataset/train/fire
! mv /content/Classification1/the_wildfire_dataset/train/fire/Smoke_from_fires/* /content/Classification1/the_wildfire_dataset/train/fire
! mv /content/Classification1/the_wildfire_dataset/train/nofire/Fire_confounding_elements/* /content/Classification1/the_wildfire_dataset/train/nofire
! mv /content/Classification1/the_wildfire_dataset/train/nofire/Forested_areas_without_confounding_elements/* /content/Classification1/the_wildfire_dataset/train/nofire
! mv /content/Classification1/the_wildfire_dataset/train/nofire/Smoke_confounding_elements/* /content/Classification1/the_wildfire_dataset/train/nofire

! mv /content/Classification1/the_wildfire_dataset/val/fire/Both_smoke_and_fire/* /content/Classification1/the_wildfire_dataset/val/fire
! mv /content/Classification1/the_wildfire_dataset/val/fire/Smoke_from_fires/* /content/Classification1/the_wildfire_dataset/val/fire
! mv /content/Classification1/the_wildfire_dataset/val/nofire/Fire_confounding_elements/* /content/Classification1/the_wildfire_dataset/test/nofire
! mv /content/Classification1/the_wildfire_dataset/val/nofire/Forested_areas_without_confounding_elements/* /content/Classification1/the_wildfire_dataset/val/nofire
! mv /content/Classification1/the_wildfire_dataset/val/nofire/Smoke_confounding_elements/* /content/Classification1/the_wildfire_dataset/val/nofire

! mv /content/Classification1/the_wildfire_dataset/* /content/Classification1

! unzip flamevision.zip

! mv /content/flames/flamesvision/* /content
! rm -r /content/flames

! mv /content/Classification1/test/fire/* /content/Classification/test/fire

! mv /content/Classification1/test/nofire/* /content/Classification/test/nofire

! mv /content/Classification1/val/fire/* /content/Classification/valid/fire

! mv /content/Classification1/val/nofire/* /content/Classification/valid/nofire

! mv /content/Classification1/train/nofire/* /content/Classification/train/nofire

! mv /content/Classification1/train/fire/* /content/Classification/train/fire

! rm -r Classification1/

#! cp -r /content/Classification/* /content/drive/MyDrive/dl_final_proj_dataset

import os
import pandas as pd
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import ImageFile
from keras import activations, Model
from tensorflow.keras.applications import VGG16, ResNet50, NASNetLarge
from tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling2D
ImageFile.LOAD_TRUNCATED_IMAGES = True
from PIL import Image
import requests
from keras.models import load_model
from io import BytesIO
from tensorflow.keras.regularizers import l2
from sklearn.metrics import confusion_matrix,classification_report
from tensorflow.keras.applications.resnet import preprocess_input
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

train_dir = "/content/Classification/train"
valid_dir = "/content/Classification/valid"
test_dir = "/content/Classification/test"

test_classes = os.listdir(test_dir)
print(test_classes)

import random

def rename_images(directory):
    for filename in os.listdir(directory):
        # Split the filename into name (name) and extension (ext)
        name, ext = os.path.splitext(filename)
        if ext.lower() in ['.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff']:  # Add or remove file extensions as needed.
            # Generate a random number as the new filename, keeping the original extension
            new_filename = f"{random.randint(1, 1000000)}{ext}"
            # Define the full file paths
            old_file = os.path.join(directory, filename)
            new_file = os.path.join(directory, new_filename)
            # Check if the new filename already exists, to avoid overwriting existing images
            while os.path.exists(new_file):
                new_filename = f"{random.randint(1, 1000000)}{ext}"
                new_file = os.path.join(directory, new_filename)
            # Rename the file
            os.rename(old_file, new_file)
            print(f"Renamed {filename} to {new_filename}")

# Paths to your valid and test directories
valid_dir = "/content/Classification/valid/fire"
test_dir = "/content/Classification/test/fire"
valid_dir_nf = "/content/Classification/valid/nofire"
test_dir_nf = "/content/Classification/test/nofire"

# Rename images in validation and test directories
rename_images(valid_dir)
rename_images(test_dir)
rename_images(valid_dir_nf)
rename_images(test_dir_nf)

def gaussian_noise(image):
    """
    Add Gaussian noise to an image.
    """
    mean = 0
    var = 10
    sigma = var ** 0.5
    gaussian = np.random.normal(mean, sigma, image.shape)  # Gaussian noise
    noisy_image = np.clip(image + gaussian, 0, 255)  # Add noise and clip the values
    return noisy_image


# ImageDataGenerator with Gaussian noise
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True,
    zoom_range=0.1,
    #channel_shift_range=20,  # Randomly shift color channels
    preprocessing_function=gaussian_noise
)

def save_augmented_images(class_name, num_images=1):
    """
    Save a specified number of augmented images for each original image in a given class.
    """
    class_dir = os.path.join(train_dir, class_name)
    images = [img for img in os.listdir(class_dir) if img.endswith((".png", "jpg", "jpeg"))]

    for img_name in images:
        img_path = os.path.join(class_dir, img_name)
        img = load_img(img_path)
        x = img_to_array(img)
        x = x.reshape((1,) + x.shape)

        # Generate and save augmented images
        for _, batch in zip(range(num_images),
                            datagen.flow(x, batch_size=1000, save_to_dir=class_dir, save_prefix='aug_' + class_name,
                                         save_format='png')):
            pass  # This loop will save 'num_images' augmented images for each original image

save_augmented_images('fire')
save_augmented_images('nofire')

input_shape = (224,224,3)
num_classes = 2

trainGenertor = ImageDataGenerator(
    preprocessing_function = preprocess_input,
    dtype = 'float32'
)
valGenertor = ImageDataGenerator(
    preprocessing_function = preprocess_input,
    dtype = 'float32'
)

testGenertor = ImageDataGenerator(
    preprocessing_function = preprocess_input,
    dtype = 'float32'
)

train_data = trainGenertor.flow_from_directory(
    train_dir,
    target_size = (224,224),
    batch_size = 16,
    class_mode = 'binary'
)

val_data = valGenertor.flow_from_directory(
    valid_dir,
    target_size = (224,224),
    batch_size = 16,
    class_mode = 'binary'
)

test_data = testGenertor.flow_from_directory(
    test_dir,
    target_size = (224,224),
    batch_size = 16,
    class_mode = 'binary',
    shuffle = False
)

ResNet50_model = ResNet50(
    include_top=False,
    weights="imagenet",
    input_shape=input_shape
)

for layer in ResNet50_model.layers:
    layer.trainable = False

model = Sequential()
model.add(ResNet50_model)  # Assuming ResNet50_model is predefined
model.add(BatchNormalization())
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.001)))
model.add(Dropout(0.7))
model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))
model.add(Dropout(0.6))
model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))
model.add(Dropout(0.6))
model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))
model.add(Dropout(0.6))
model.add(Dense(1, activation='sigmoid')) # For binary classification, consider using 'sigmoid'

model.summary()

model.compile(
    optimizer='sgd',
    loss='binary_crossentropy', # Note: For binary classification, this is typically used with 'sigmoid' activation
    metrics=['accuracy']
)
callbacks = [
    tf.keras.callbacks.EarlyStopping(patience=5),
    tf.keras.callbacks.ModelCheckpoint('model.h5', save_best_only=True),
    tf.keras.callbacks.TensorBoard(log_dir='logs')
]

results = model.fit(train_data,validation_data=val_data,epochs=5,verbose = 1)

loss, acc = model.evaluate(test_data,verbose = 1)

predictions_prob = model.predict(test_data)
predictions = (predictions_prob > 0.5).astype("int32")
true_labels = test_data.classes
report = classification_report(true_labels, predictions)
print(report)

conf_mat = confusion_matrix(true_labels, predictions)
sns.heatmap(conf_mat, fmt='g', annot=True, cmap='Blues', xticklabels=['nofire', 'fire'], yticklabels=['nofire', 'fire'])
plt.xlabel('Predictions')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

res = results.history
train_acc = res['accuracy']
val_accuracy = res['val_accuracy']
epochs = range(1, len(train_acc) + 1)

line1 = plt.plot(epochs, val_accuracy, label = 'Validation/Test Accuracy')
line2 = plt.plot(epochs, train_acc, label = 'Training Accuracy')

plt.setp(line1, linewidth = 1.8, marker = 'o', markersize = 6.5)
plt.setp(line2, linewidth = 1.8, marker = 's', markersize = 5)
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.grid(True)
plt.legend()
plt.show()

res = results.history
train_loss = res['loss']
val_loss = res['val_loss']
epochs = range(1, len(train_loss) + 1)

line1 = plt.plot(epochs, val_loss, label = 'Validation/Test Loss')
line2 = plt.plot(epochs, train_loss, label = 'Training Loss')

plt.setp(line1, linewidth = 1.8, marker = 'o', markersize = 6.5)
plt.setp(line2, linewidth = 1.8, marker = 's', markersize = 5)
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.grid(True)
plt.legend()
plt.show()

model.save('model.h5')

def get_user_input():
    """
    Get image input from the user, either as a file path or a URL.
    """
    choice = input(
        "Enter '1' to upload a direct image URL (must end with .jpg, .jpeg, .png, etc.) or '2' to upload an image from your computer: ")
    if choice == '1':
        image_url = input("Enter the direct image URL: ")
        if image_url.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):
            return image_url, True
        else:
            print("Please enter a valid image URL that ends with image extension type.")
            return None, None
    elif choice == '2':
        image_path = input("Enter the path to your image file: ")
        return image_path, False
    else:
        print("Invalid input. Please enter '1' or '2'.")
        return None, None

def load_and_preprocess_image(image_path_or_url, from_url):
    """
    Load and preprocess an image from a local path or a URL.
    """
    if from_url:
        # Load the image from a URL
        response = requests.get(image_path_or_url)
        image = Image.open(BytesIO(response.content))
    else:
        # Load the image from a local file
        image = Image.open(image_path_or_url)
    '''
    # Resize image and convert to RGB (3 channels)
    image = image.resize((224, 224)).convert('RGB')

    # Convert image to array and normalize
    image = img_to_array(image) / 255.0

    # Expand dimensions to match the model's input format
    image = np.expand_dims(image, axis=0)
    '''
    # Resize the image to match the model's expected input size
    img = image.resize((224, 224))

    # Convert the image to RGB if it's not already
    if img.mode != 'RGB':
        img = img.convert('RGB')

    # Convert the PIL Image to a numpy array
    img_array = img_to_array(img)

    # Apply the same preprocessing as during training
    img_array = preprocess_input(img_array)

    # Add a batch dimension
    img_array = np.expand_dims(img_array, axis=0)

    return img_array

def predict_image(model, image_path_or_url, from_url):
    """
    Predict whether an image contains fire or no fire.
    """
    # Load and preprocess the image
    processed_image = load_and_preprocess_image(image_path_or_url, from_url)

    # Predict
    prediction = model.predict(processed_image)

    # Interpret prediction
    class_names = ['fire', 'nofire']
    class_index = np.argmax(prediction)
    predicted_class = class_names[class_index]

    return predicted_class

# image prediction
model = load_model('model.h5')
image_path_or_url, from_url = get_user_input()
prediction = predict_image(model, image_path_or_url, from_url)
print("Prediction:", prediction)

train_filenames = set(os.listdir(train_dir))
val_filenames = set(os.listdir(valid_dir))
test_filenames = set(os.listdir(test_dir))

overlap_train_val = train_filenames.intersection(val_filenames)
overlap_train_test = train_filenames.intersection(test_filenames)
overlap_val_test = val_filenames.intersection(test_filenames)

print("Overlap between train and validation:", overlap_train_val)
print("Overlap between train and test:", overlap_train_test)
print("Overlap between validation and test:", overlap_val_test)

import os
import hashlib

def file_hash(filepath):
    with open(filepath, 'rb') as f:
        return hashlib.md5(f.read()).hexdigest()

def get_hashes(directory):
    return {fname: file_hash(os.path.join(directory, fname)) for fname in os.listdir(directory) if os.path.isfile(os.path.join(directory, fname))}

# Get hashes for each image in each dataset
train_hashes = get_hashes(train_dir)
val_hashes = get_hashes(valid_dir)
test_hashes = get_hashes(test_dir)

# Find duplicates between training and validation
duplicates_train_val = {fname for fname, hashval in train_hashes.items() if hashval in val_hashes.values()}
# Find duplicates between training and test
duplicates_train_test = {fname for fname, hashval in train_hashes.items() if hashval in test_hashes.values()}
# Find duplicates between validation and test
duplicates_val_test = {fname for fname, hashval in val_hashes.items() if hashval in test_hashes.values()}

print("Duplicates between train and validation:", duplicates_train_val)
print("Duplicates between train and test:", duplicates_train_test)
print("Duplicates between validation and test:", duplicates_val_test)

